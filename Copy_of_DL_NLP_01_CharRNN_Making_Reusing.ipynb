{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ordevoir/Algorithms/blob/main/Copy_of_DL_NLP_01_CharRNN_Making_Reusing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7d-TaRR9QTp"
      },
      "source": [
        "# Character RNN\n",
        "\n",
        "Character RNN (или Char RNN) может прогнозировать следующий символ в предложении. Построим и обучим Char RNN, способную генерировать новый текст."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MpbNOEf9QTs"
      },
      "source": [
        "## Создание тренировочного датасета\n",
        "\n",
        "Загрузим все работы Шекспира функцией `tf.keras.utils.get_file()`. Данные загружаются из проекта Андрея Карпаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Qgf6qVxw9QTs",
        "outputId": "6b0105b2-4f07-4ac3-ccd9-1ccff669636f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/shakespeare.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()\n",
        "filepath        # путь по которому лежит загруженный файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3Ged5oT9QTt",
        "outputId": "6bebc6a2-bb0d-4362-d6e5-be45bc5d4615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:173])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8LvITw9QTu"
      },
      "source": [
        "Воспользуемся слоем `TextVectorization` (который описан в файле Load_and_Preprocesing) для кодирования этого текста. Установим `split=\"character\"` для получения кодирования на уровне символов, а не слов, как то задано по умолчанию. Также установим `standardize=\"lower\"` для конвертирования текста в нижний регистр (это упростит задачу):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzibHbHH9QTu",
        "outputId": "14aa4e89-7fcd-47ba-85a5-1c98292dc535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]\n",
        "encoded     # кодированный текст"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-7tn3zG9QTu"
      },
      "source": [
        "Каждому символу поставлено в соответствие целое число, начиная с 2 (1 зарезервирована под неизвестные символы, а 0 – для отступов). Мы не нуждаемся в этих двух токенах, поэтому вычтем 2 из массива `encoded`, посчитаем число токенов и число символов в датасете:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okFiHts9QTv",
        "outputId": "012ca710-25e4-4c41-8e70-d194f92dcf23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 1115394)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "encoded -= 2\n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
        "dataset_size = len(encoded)\n",
        "n_tokens, dataset_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NIV0c719QTv"
      },
      "source": [
        "Теперь превратим эту длинную последовательность в датасет окон для того, чтобы использовать их при обучении sequence-to-sequence RNN. Цели (targets) будут совпадать с входами (inputs), но с единичным смещением в будущее. Например, один образец в датасете может быть полсдеовательностью ID символов, представляющих текст \"to be or not to b\", и соответствующий ему target – последовательность ID символов, представляющих текст \"o be or not to be\". Напишем функцию, которая конвертирует длинную последовательность ID символов в датасет input/target пар:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlKKhs-x9QTv"
      },
      "outputs": [],
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CmKLANY9QTw"
      },
      "source": [
        "Статический метод `from_tensor_slices()` превратит все элементы последовательности в отдельные образцы. Методы `from_tensor_slices()`, `batch()`, `window()`, `map()` `flat_map()` , `batch()` и `shuffle()` – описаны в Load_and_Preprocessing_Data. Разбор некоторых компонентов функции `to_dataset()` приведен ниже.\n",
        "\n",
        "Теперь можно создать тренировочный, валидационный и тестовый наборы. 90% будет отведено на тренировочный набор, а на валидационный и тестовый – по 5%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPVvdJhA-M5f"
      },
      "outputs": [],
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length,\n",
        "                       shuffle=True)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length = length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc8hDN2PkUEH"
      },
      "source": [
        "Датасет `train_set` содержит последовательность кортежей, содрежащих пару (input, ouput). Каждый input представляет собой тензор с формой (32, 100), т.е. партия из 32 образцов, а каждый образец – длиной в 100 токенов. Такую же форму имеет и output, и отличается от input лишь тем, что каждый образец смещен на 1 вперед во времени."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLkT3X2RkUEI",
        "outputId": "cb1c3f33-3166-454e-c7c1-6cedc9d5aa6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:\n",
            " tf.Tensor(\n",
            "[[ 1  9  2 ...  0 12  5]\n",
            " [ 9  5 13 ... 10  4  9]\n",
            " [ 2  6  1 ...  3 27  2]\n",
            " ...\n",
            " [ 3 22  1 ...  0 14  1]\n",
            " [20 20  4 ...  0  9  3]\n",
            " [ 2  6  1 ...  0 22  1]], shape=(32, 100), dtype=int64)\n",
            "ouput:\n",
            " tf.Tensor(\n",
            "[[ 9  2 11 ... 12  5 12]\n",
            " [ 5 13  7 ...  4  9 12]\n",
            " [ 6  1  7 ... 27  2 26]\n",
            " ...\n",
            " [22  1 23 ... 14  1 17]\n",
            " [20  4  8 ...  9  3  0]\n",
            " [ 6  1 15 ... 22  1  3]], shape=(32, 100), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for item in train_set:\n",
        "    print(f\"input:\\n\", item[0])\n",
        "    print(f\"ouput:\\n\", item[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LQfyPT3-TAF"
      },
      "source": [
        "Мы установили длину окна равной 100, но можно пробовать ее менять: RNN легче и быстрее обучать на более коротких входных последовательностях, но при этом она не сможет изучить какой-либо паттерн длиннее `length`, поэтому не следует делать ее слишком маленькой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKzxvyAt-WY9"
      },
      "source": [
        "### Разбор функции `to_dataset()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DylTKZ019QTw",
        "outputId": "97535a63-0277-498e-97c6-956db61a1b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "seq = tf.range(7)      # создаем последовательность\n",
        "print(seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t5KaUA69QTw"
      },
      "source": [
        "Создаем из последовательности объект `Dataset`, в котором образцы представлены в виде тензоров (в данном случае нулевого ранга)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1e7Vhme9QTw",
        "outputId": "6fafb6c0-67e7-4de4-f5d4-07b5726b9691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset'>\n",
            "0 1 2 3 4 5 6 \n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
            "тензор нулевого ранга:\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices(seq)\n",
        "print(type(ds))\n",
        "for item in ds:\n",
        "    print(f\"{item}\", end=' ')\n",
        "for item in ds:\n",
        "    print(f\"\\n{type(item)} \\nтензор нулевого ранга:\")\n",
        "    print(item)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH122kW99QTw"
      },
      "source": [
        "Получим окна (объект класса `_WindowDataset`) со сдвигом 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eE5uzBq9QTw",
        "outputId": "aef06a0d-d586-4484-b5ec-29eb196b5d95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(ds_windows) = <class 'tensorflow.python.data.ops.window_op._WindowDataset'>\n",
            "0 1 2 3  window, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "1 2 3 4  window, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "2 3 4 5  window, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "3 4 5 6  window, <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ],
      "source": [
        "length = 3\n",
        "ds_windows = ds.window(size=length+1, shift=1, drop_remainder=True)\n",
        "print(f\"{type(ds_windows) = }\")\n",
        "for window in ds_windows:\n",
        "    for e in window:\n",
        "        print(f\"{e}\", end=' ')\n",
        "    print(f\" window, {type(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPatCSZNkUEQ"
      },
      "source": [
        "Сейчас образцы в `ds` представляют собой объекты класса `_VariantDataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42lk0tWN9QTx",
        "outputId": "742c8a24-c1a5-4d08-8ccd-130801ce7083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'>\n",
            "<class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'>\n",
            "<class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'>\n",
            "<class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'>\n"
          ]
        }
      ],
      "source": [
        "for item in ds_windows:\n",
        "    print(type(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY7G8tAH9QTx"
      },
      "source": [
        "При вызове метода `flat_map()`, все отдельные объекты `_VariantDataset` будут выпрямлены в один объект `_VariantDataset` и переданы в преобразующую [`lambda`] функцию. Функция разобъет эту общую последовательность на последовательности длины `length+1` методом `batch()`. Фактически мы конвертируем объекты класса `_VariantDataset` в тензоры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiEX_ZFm9QTx",
        "outputId": "1db2e15c-9527-4cb1-cb42-c48bb16bde9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
            "tf.Tensor([2 3 4 5], shape=(4,), dtype=int32)\n",
            "tf.Tensor([3 4 5 6], shape=(4,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "ds_flatten = ds_windows.flat_map(lambda v: v.batch(length+1))\n",
        "\n",
        "for item in ds_flatten:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay0ULQgFkUEU"
      },
      "source": [
        "Разбиваем последовательность тензоров на партии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkUOkHNRkUEU",
        "outputId": "6a766e3d-4171-41a5-fec8-adf106585d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0 1 2 3]\n",
            " [1 2 3 4]], shape=(2, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[2 3 4 5]\n",
            " [3 4 5 6]], shape=(2, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2\n",
        "ds_batched = ds_flatten.batch(batch_size)\n",
        "for item in ds_batched:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqaE6ppFkUEW"
      },
      "source": [
        "Осталось получить inputs и outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djk3apXjkUEX",
        "outputId": "131cb5de-8e6d-4a3b-8d8e-2b530fd97e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "array([[0, 1, 2],\n",
            "       [1, 2, 3]])>, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "array([[1, 2, 3],\n",
            "       [2, 3, 4]])>)\n",
            "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "array([[2, 3, 4],\n",
            "       [3, 4, 5]])>, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "array([[3, 4, 5],\n",
            "       [4, 5, 6]])>)\n"
          ]
        }
      ],
      "source": [
        "result = ds_batched.map(lambda window: (window[:, :-1], window[:, 1:]))\n",
        "for item in result:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Gs4SEYkUEY"
      },
      "source": [
        "Итоговый датасет представляет собой последовательность кортежей, состоящих из пар тензоров (inputs, outputs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPhQRdle9QTx"
      },
      "source": [
        "![](https://raw.githubusercontent.com/ordevoir/Miscellaneous/master/images/nn/shuffled_windows.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNc1-S2B9QTx"
      },
      "source": [
        "## Построение и обучение модели\n",
        "\n",
        "Построим модель с GRU слоем, составленным из 128 нейронов и обучим ее:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "vOYLrk2h9QTx",
        "outputId": "468db226-5048-49dd-8ffb-096da80cf2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2e1a1013d046>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"shakespeare_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     save_best_only=True)\n\u001b[0;32m---> 11\u001b[0;31m history = model.fit(train_set, validation_data=valid_set,\n\u001b[0m\u001b[1;32m     12\u001b[0m                     epochs=10, callbacks=[model_ckpt])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"shakespeare_model\", monitor=\"val_accuracy\",\n",
        "    save_best_only=True)\n",
        "history = model.fit(train_set, validation_data=valid_set,\n",
        "                    epochs=10, callbacks=[model_ckpt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB_xs5OC9QTy"
      },
      "source": [
        "Здесь используется слой `Embedding`, описанный в Load_and_Preprocessing_Data. Этот слой ставит в соответствие IDs символов точки в 16-мерном пространстве. На вход слой будет получать 2D тензоры с формой [*batch size, window length*], а возврщащать слой будет 3D тензор с формой [*batch size, window length, embedding size*] (embedding size в данном случае задан как `output_dim=16`).\n",
        "\n",
        "Слой `Dense` должен состоять из 39 нейронов (`n_tokens`), так как всего имеется 39 различных символов в тексте, и мы хотим получать вероятности для каждого возможного символа (на каждом временнóм шаге). В сумме все эти вероятности должны давать 1 на каждом временнóм шаге, так что применяется функция активации softmax.\n",
        "\n",
        "Данная модель не производит предобработку текста, поэтому имеет смысл обернуть ее в финальную модель, которая будет содержать слой `tf.keras.layers.TextVectorization` в качестве первого слоя. Также добавим слой `tf.keras.layers.Lambda` для вычитания 2 из IDs символов, так как мы не будтем использовать отступы и неизестные токены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk8aaq9K9QTy"
      },
      "outputs": [],
      "source": [
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_NGaW1l9QTy"
      },
      "source": [
        "### Загрузка обученной модели\n",
        "\n",
        "Обучение на GPU в Colab может занять несколько часов. Можно скачать предобученную Geron'ом модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND6Xhff4kUEf",
        "outputId": "89ebd066-be1f-49d2-e5b6-a350e854ddca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wernadsky\\.keras\\datasets\\shakespeare_model\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
        "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\n",
        "model_path = Path(path).with_name(\"shakespeare_model\")\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybxn57sIkUEf"
      },
      "source": [
        "Используем загруженную модель вместо построенной выше:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kcsG8U7kUEg",
        "outputId": "01b385d9-a14c-4ad9-b23c-1cc06304e5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "shakespeare_model = tf.keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO5IE5DQkUEj"
      },
      "source": [
        "Проверим на известном примере:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VafM_WeukUEk",
        "outputId": "e27e95f3-7144-4cda-fde4-162d7a223bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 418ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
        "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
        "text_vec_layer.get_vocabulary()[y_pred + 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTL-GV-MkUEl"
      },
      "source": [
        "## Генерация текста\n",
        "\n",
        "Для того, чтобы сгенерировать текст, используя модель char-RNN, мы должны скормить ей некоторый текст, дать модели спрогнозировать наибольее вероятную следующую букву, и добавить это в конец текста, задем дать дать этот расширенный текст модели для угадывания следующей буквы и тд. Это называется **greedy decoding**. Но на практике это часто приводит к тому, что одно и то же слово повторяется снова и снова. Вместо этого, мы можем выбрать следующий символ случайно, с соответствии с распределением вероятностей, данным в прогнозе. Для этого можно использовать функцию `tf.random.categorical()`, которая будет генерировать более разнообразный и интересный текст.\n",
        "\n",
        "Функция `tf.random.categorical()` принимает логарифмированные вероятности классов, и выбирает индекс класса. В аргументе `num_samples` можно задать количество генерируемых обазцов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzJL9b0HkUEm",
        "outputId": "a7208372-ce59-402b-f594-8ff877012acd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[1, 0, 1, 1, 1, 0, 2, 1]], dtype=int64)>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_probas = tf.math.log([[0.5, 0.4, 0.1]])\n",
        "tf.random.categorical(log_probas, num_samples=8)  # draw 8 samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDZprw2lkUEn"
      },
      "source": [
        "Для того, чтобы иметь больше контроля над разнообразием генерируемого текста, мы можем разделить логарифмы на число, называемое **температурой**. Температура, близкая к нулю способствует \"контрастированию\" вероятностей символов, в то время как высокая температура уравнивает вероятности для всех символов. Низкая температура обычно предпочтительна при генерации довольно ригидного и точного текста, такого как математическое уравнение, в то время как высокая температура предпочтительней при генерации более разнообразного и креативного текста.\n",
        "\n",
        "Функция `next_char()` будет помагать выбрать следующий символ для добавления во входящий текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VgcM21EkUEo"
      },
      "outputs": [],
      "source": [
        "def next_char(text, temperature=1):\n",
        "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits,\n",
        "                                    num_samples=1)[0, 0]\n",
        "    return text_vec_layer.get_vocabulary()[char_id + 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVHzUPMQkUEp"
      },
      "source": [
        "Далее мы можем написать другую вспомогательную функцию `extend_text()`, которая будет вызывать в цикле функцию `next_char()` для получения следующего символа и добавления его в заданный текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55YrQeUvkUEp"
      },
      "outputs": [],
      "source": [
        "def extend_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lip0JtTGkUEq"
      },
      "source": [
        "Произведем генерацию при различных температурах (0.01, 1, 100):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi9Oq1l-kUEr",
        "outputId": "c5165cac-7694-4051-c279-180974f92d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To be or not to b on the strange daughter\n",
            "to the death and the death\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "generated = extend_text(\"To be or not to b \", temperature=0.01)\n",
        "clear_output()\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTnUJGFmkUEs",
        "outputId": "b5c6de37-b67a-429d-e98a-e88a02ab02c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To be or not to be but a commody to her provost.\n",
            "\n",
            "claudio:\n",
            "why do you speak to angelo.\n",
            "\n",
            "petruchio:\n",
            "a playalliats, thou hast the heavens so that course.\n",
            "\n",
            "lucio:\n",
            "i am a pains he hath made the very noble thing,\n",
            "so i would not see the issue of the news with his life\n",
            "to death is not you a thousand haste to sent to heard your master's\n",
            "head to me the head should be the sacred a state,\n",
            "and would i know him and here, i know this sheewer,\n",
            "and i think it is a streak with the prison,\n",
            "and make me too much soundly be to execu\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "generated = extend_text(\"To be or not to b\", temperature=.5)\n",
        "clear_output()\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQdbD8XlkUEt",
        "outputId": "b4637d4d-b1d6-4678-a89c-fab43a0412e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To be or not to berhpmflkbn'ojsgeuwt?o!r.s?iszc\n",
            "rgabtfd$\n",
            "peruvdok.t.\n"
          ]
        }
      ],
      "source": [
        "generated = extend_text(\"To be or not to be\", temperature=100)\n",
        "clear_output()\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-qwy3RTkUEu"
      },
      "source": [
        "Для генерации более убедительного текста, обычной практикой является отбор только из $k$ наиболее вероятных символов, или только из небольшого набора символов, чьи вероятности превышают некоторый порог (это называется *nucleus sampling*).\n",
        "\n",
        "Алтернативный вариант – использовать *beam search* (см. ниже), или использование большего чисало GRU слоев и больше нейронов на слой, более длительное обучение, и добавление регуларизации при необходимости.\n",
        "\n",
        "Следует также заметить, что модель не способна уловить паттерны длиннее `lenght`, который составляет 100 символов. Можно попробовать сделать ширину окна больше, но это также усложнит обучение, и даже LSTM и GRU cells не смогут обрабатывать очень длинные последовательности. Альтернативным вариантом является использование stateful RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b56fx7yBkUEu"
      },
      "source": [
        "## Stateful RNN\n",
        "\n",
        "До сих пор мы использовали только **stateless RNNs**: на каждом экземпляре (полсдовательность из 100 шагов) модель стартует с hidden state, заполненного нулями, и это состояние обновляется на каждом временнóм шаге, и после последнего шага состояние выбрасывается за ненадобностью. Поэтому, на текущем временном шаге влияние оказывают лишь предыдущие значения данной последовательности, в то время как предыдущая посделовательность влияния не оказывает, так как hidden state не хранит о них информацию. Таким образом, stateles RNN обрабатывает последовательности независимо.\n",
        "\n",
        "**Stateful RNNs** характерен тем, что hidden state сохраняет память между последовательностями, улавливая долгосрочные зависимости. Поэтому, stateful RNNs используются, когда порядок и непререрывность последовательностей имеет существенное значение. В stateful RNN скрытое состояние RNN после обработки одной последовательности используется как начальное состояние для следующей последовательности.\n",
        "\n",
        "Будем предполагать, что в начале прохождения $i$-ой последовательности текущей партии, hidden state инициализируется финальным значением hidden state после прохождения на $i$-ой последовательности *предыдущей* партии. Поэтому, при формировании партий, каждая $i$-ая последовательность партии длжна быть продолжением $i$-ой последовательности предыдущей партии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trDYG3Z8kUEv"
      },
      "source": [
        "### Подготовка данных\n",
        "\n",
        "Для того, чтобы чтобы использовать stateful RNN, необходимо иначе подготовить данные, чтобы последовательности шли друг за другом последовательно, без перекрытий (выше мы использовали перекрывающиеся последовательности, и еще перемешивали их). При создании объекта `tf.data.Dataset` мы долджны использовать `shift=lenght` (вместо `shift=1`), затем вызвыать метод `window()`. И, конечно, мы не долждны вызывать метод `shuffle()`.\n",
        "\n",
        "Формирование партий посложней, когда данные препарируются для stateful RNN, чем для stateless RNN. Предположим, мы разбили исходный текст так, что имется последовательность окон, каждое из которых является продолжением предыдущего окна. Так, если просто вызвать `batch(32)`, то 32 окна, следующих друг за другом, будут помещены в одну партию, а следующие 32 окна – в следующую партию. Это нам не подходит, так как каждая $i$-ая последовательность партии длжна быть продолжением $i$-ой последовательности предыдущей партии. Простейшее решение этой проблемы – использовать партии размером 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyL0m3lRkUEw"
      },
      "outputs": [],
      "source": [
        "def to_dataset_for_stateful_rnn(sequence, length):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "length = 100\n",
        "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
        "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length)\n",
        "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAusyj8SkUEx",
        "outputId": "9fdd1377-d3b2-487e-ebbc-298678eaf5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:\n",
            " tf.Tensor(\n",
            "[[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
            "   0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
            "   4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
            "  17  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23\n",
            "  10 15  3 13]], shape=(1, 100), dtype=int64)\n",
            "ouput:\n",
            " tf.Tensor(\n",
            "[[ 5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0\n",
            "  22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4\n",
            "   8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17\n",
            "   0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10\n",
            "  15  3 13  0]], shape=(1, 100), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for item in stateful_train_set:\n",
        "    print(f\"input:\\n\", item[0])\n",
        "    print(f\"ouput:\\n\", item[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnXYuv-WkUEx"
      },
      "source": [
        "Создать партии в общем-то можно. К примеру, можно нарезать весь текст на 32 фрагмента равной длины, создать один датасет отбирая из каждого фрагмента последовательность по очереди. Получим 32 последовательности из каждого фрагмента, затем еще 32 последовательности и так по кругу, пока фрагменты не исчерпаются.\n",
        "\n",
        "![](https://raw.githubusercontent.com/ordevoir/Miscellaneous/master/images/nn/prepare_for_stateful_rnn.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KJ5LALJkUEy",
        "outputId": "36f36a03-a3bb-4a2a-c030-703184bfdb97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 0,  1,  2],\n",
              "         [10, 11, 12]])>,\n",
              "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 1,  2,  3],\n",
              "         [11, 12, 13]])>),\n",
              " (<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 3,  4,  5],\n",
              "         [13, 14, 15]])>,\n",
              "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 4,  5,  6],\n",
              "         [14, 15, 16]])>),\n",
              " (<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 6,  7,  8],\n",
              "         [16, 17, 18]])>,\n",
              "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "  array([[ 7,  8,  9],\n",
              "         [17, 18, 19]])>)]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def to_non_overlapping_windows(sequence, length):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "    return ds.flat_map(lambda window: window.batch(length + 1))\n",
        "\n",
        "def to_batched_dataset_for_stateful_rnn(sequence, length, batch_size=32):\n",
        "    parts = np.array_split(sequence, batch_size)\n",
        "    datasets = tuple(to_non_overlapping_windows(part, length) for part in parts)\n",
        "    ds = tf.data.Dataset.zip(datasets)\n",
        "    ds = ds.map(lambda *windows: tf.stack(windows))\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "list(to_batched_dataset_for_stateful_rnn(tf.range(20), length=3, batch_size=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wMM73T3kUEy"
      },
      "source": [
        ">Ниже приведен подробный разбор функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ2PFPXrkUEz"
      },
      "outputs": [],
      "source": [
        "length = 100\n",
        "batch_stateful_train_set = to_batched_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
        "batch_stateful_valid_set = to_batched_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length)\n",
        "batch_stateful_test_set = to_batched_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBZD0lvEkUE0"
      },
      "source": [
        "### Построение и обучение модели\n",
        "\n",
        "Создадим модель stateful RNN. Для этого в слое `GRU` необходимо задать аргумент `stateful=True`, и так как это stateful RNN, сеть должна знать размер партии (так как он должен будет хранить состояние для каждой входной последовательности в партии). Таким образом, мы должны задать аргумент `batch_input_shape` в первом слое. Заметим, что мы можем оставить вторую размерность неопределенной (`None`), так как в общем случае входные последовательности для RNN могут иметь любую длину:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPk8PfCakUE0"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16,\n",
        "                              batch_input_shape=[32, None]),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCHAUhKxkUE1"
      },
      "source": [
        "В конце каждой эпохи мы должны сбрасывать состояние, прежде чем мы будем возвращаться к началу текста. Для этого мы можем написать пользовательский callback, который в начале каждой эпохи будет сбрасывать состояние, вызывая у модели метод `reset_states()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAqcKrWkUE1"
      },
      "outputs": [],
      "source": [
        "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGxCQBQkkUE2",
        "outputId": "d23ccb38-a036-43dc-b7eb-c6493ae83c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 4s 104ms/step - loss: 3.5668 - accuracy: 0.1339 - val_loss: 3.1944 - val_accuracy: 0.1521\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 3.1282 - accuracy: 0.1461 - val_loss: 3.0831 - val_accuracy: 0.1521\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 3.0793 - accuracy: 0.1461 - val_loss: 3.0663 - val_accuracy: 0.1521\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 3.0698 - accuracy: 0.1461 - val_loss: 3.0587 - val_accuracy: 0.1521\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 3.0617 - accuracy: 0.1461 - val_loss: 3.0485 - val_accuracy: 0.1521\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 3.0480 - accuracy: 0.1461 - val_loss: 3.0299 - val_accuracy: 0.1521\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 3.0224 - accuracy: 0.1462 - val_loss: 2.9953 - val_accuracy: 0.1521\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 2.9766 - accuracy: 0.1465 - val_loss: 2.9358 - val_accuracy: 0.1527\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 2.9028 - accuracy: 0.1790 - val_loss: 2.8467 - val_accuracy: 0.2202\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 2.8027 - accuracy: 0.2408 - val_loss: 2.7394 - val_accuracy: 0.2580\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(batch_stateful_test_set,\n",
        "                    validation_data=batch_stateful_valid_set,\n",
        "                    epochs=10, callbacks=[ResetStatesCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT4v5qWZkUE2"
      },
      "source": [
        ">После того, как модель обучена, прогнозы можно будет получить только для партий того же размера, что использовалось в обучении. Для того, чтобы снять такое ограничение, можно создать такую же stateless сеть, и скопировать в нее параметры stateful модели.\n",
        "\n",
        "Интересно, что хотя модель char-RNN просто обучена предсказывать следующий символ, эта, казалось бы, простая задача на самом деле требует от нее также изучения некоторых паттернов более высокого уровня. Например, чтобы найти следующий символ после «Отличный фильм, я действительно», полезно понимать, что предложение положительное, поэтому далее, скорее всего, будет буква «л» (что означает «любимый»), а не «н». (для «ненавижу»). Фактически, в статье Alec Radford и других исследователей OpenAI, опубликованной в 2017 году, описывается, как авторы обучили большую charRNN-подобную модель на большом наборе данных и обнаружили, что один из нейронов действует как отличный классификатор анализа настроения (*sentiment neuron*): хотя модель была обучена без каких либо меток настроения, нейрон настроения достиг самых высоких результатов в тестах анализа настроений. Это мотивировало к предварительном обучению NLP без учителя."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oghdMRQekUE3"
      },
      "source": [
        "### Разбор функций\n",
        "\n",
        "Функция `to_non_overlapping_windows()` похожа на `to_dataset_for_stateful_rnn()` но без хвоста (batching). Она возвращает датасет из непересекающихся окон, каждое из которых является продолжением следующего. A batching осуществляется функцией `to_batched_dataset_for_stateful_rnn()`. Она берет исходную последовательность, и нарезает ее на 32 (`batch_size`) фрагмента, используя функцию `np.array_split()`. К каждой из фрагментов применяется функция `to_non_overlapping_windows()` и результаты (окна) собираются в кортеж `datasets`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c8n7v7IkUE5",
        "outputId": "e689f459-47f2-47ed-f78a-77df0af82711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<_FlatMapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>,\n",
              " <_FlatMapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>,\n",
              " <_FlatMapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>,\n",
              " <_FlatMapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>)"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 4\n",
        "length = 5\n",
        "sequence = np.arange(60)\n",
        "parts = np.array_split(sequence, batch_size)\n",
        "datasets = tuple(to_non_overlapping_windows(part, length) for part in parts)\n",
        "datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsQ_7WXFkUE6"
      },
      "source": [
        "Статический метод `zip()` проходится параллельно по элементам кортежа, и на каждой итерации отбирает по одному окну, собирая каждый раз по 32 окна в новый кортеж. Метод возвращает объект класса `_ZipDataset`, содержащий кортежи длины `batch_size`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07rFMvfYkUE6",
        "outputId": "f8fdeef3-b361-4c14-957c-000e9f3647e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(ds) = <class 'tensorflow.python.data.ops.zip_op._ZipDataset'>\n",
            "len(e)  = 4\n",
            "type(e) = <class 'tuple'>\n"
          ]
        }
      ],
      "source": [
        "ds = tf.data.Dataset.zip(datasets)\n",
        "print(f\"{type(ds) = }\")\n",
        "for e in ds:\n",
        "    print(f\"{len(e)  = }\")\n",
        "    print(f\"{type(e) = }\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5PEjgDQkUE7"
      },
      "source": [
        "Посмотрим, что за кортежи:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovv1RY0YkUE8",
        "outputId": "be4e4cfa-b5a8-4b46-c677-44e42e88c515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int32)\n",
            "tf.Tensor([15 16 17 18 19 20], shape=(6,), dtype=int32)\n",
            "tf.Tensor([30 31 32 33 34 35], shape=(6,), dtype=int32)\n",
            "tf.Tensor([45 46 47 48 49 50], shape=(6,), dtype=int32)\n",
            "\n",
            "tf.Tensor([ 5  6  7  8  9 10], shape=(6,), dtype=int32)\n",
            "tf.Tensor([20 21 22 23 24 25], shape=(6,), dtype=int32)\n",
            "tf.Tensor([35 36 37 38 39 40], shape=(6,), dtype=int32)\n",
            "tf.Tensor([50 51 52 53 54 55], shape=(6,), dtype=int32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for e in ds:\n",
        "    for item in e:\n",
        "        print(item)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt3YUunfkUE9"
      },
      "source": [
        "Здесь мы видим, что $i$-ый элемент кортежа представляет собой последовательность (`Tensor`), которая является продолжением $i$-го элемента предыдущего кортежа.\n",
        "\n",
        ">Здесь, правда, есть наложение: третий элемент второго кортежа начинается с 35, а третий элемент первого кортежа заканчивается также на 35. Но заметим, что длины этих последовательностей равны 6 (`length+1`). При формировании inputs будут использованы первые 5 элементов последовательности, а при формированиии outputs – последние 5. Поэтому в результирующих партиях наложения не будет.\n",
        "\n",
        "Фактически, партии уже распределены, остается лишь превратить кортежи в тензоры и сформировать inputs и outputs.\n",
        "\n",
        "Воспользуемся методом `map()`, для того, чтобы объединить элементы (тензоры ранга 2) каждого кортежа в тензор ранга 2. Датасет `ds` состоит из двух кортежей, каждый из которых содержит по 4 тензора. Поэтому, при вызове метода `map()` в обрабатывающую [`lambda`] функцию будут передаваться тензоры из кортежа, как отдельные аргументы. Так что необходимо запаковывать их в кортеж (`*windows`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xI0BPAhkUE-",
        "outputId": "280f402d-90f7-4711-93ec-126ce9ebe074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(ds) = <class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [15 16 17 18 19 20]\n",
            " [30 31 32 33 34 35]\n",
            " [45 46 47 48 49 50]], shape=(4, 6), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 5  6  7  8  9 10]\n",
            " [20 21 22 23 24 25]\n",
            " [35 36 37 38 39 40]\n",
            " [50 51 52 53 54 55]], shape=(4, 6), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "ds = ds.map(lambda *windows: tf.stack(windows))\n",
        "print(f\"{type(ds) = }\")\n",
        "for item in ds:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpl6s_7kUE_"
      },
      "source": [
        "На данном этапе датасет `ds` представляет собой объект класса `_MapDataset`, в котором содержится 2 тензора ранга 2. Количество тензоров в общем случае зависит от исходного объема данных и соответствует итоговому количеству партий.\n",
        "\n",
        "Теперь сформируем inputs и outputs, снова воспользовавшись методом `map()`. На этот раз элементами датасета являются тензоры, а не кортежи, поэтому в обрабатывающую функцию на каждой итерации будет передаваться один аргумент (`window`). В целом, тот этап идентичен тому, что было в `to_dataset()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgLdzIuekUE_",
        "outputId": "3d1d7978-6e28-422d-8e0f-3617a669fd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch 0:\n",
            " item 0: \n",
            "[[ 0  1  2  3  4]\n",
            " [15 16 17 18 19]\n",
            " [30 31 32 33 34]\n",
            " [45 46 47 48 49]]\n",
            " item 1: \n",
            "[[ 1  2  3  4  5]\n",
            " [16 17 18 19 20]\n",
            " [31 32 33 34 35]\n",
            " [46 47 48 49 50]]\n",
            "batch 1:\n",
            " item 0: \n",
            "[[ 5  6  7  8  9]\n",
            " [20 21 22 23 24]\n",
            " [35 36 37 38 39]\n",
            " [50 51 52 53 54]]\n",
            " item 1: \n",
            "[[ 6  7  8  9 10]\n",
            " [21 22 23 24 25]\n",
            " [36 37 38 39 40]\n",
            " [51 52 53 54 55]]\n"
          ]
        }
      ],
      "source": [
        "result = ds.map(lambda window: (window[:, :-1], window[:, 1:]))\n",
        "for i, batch in enumerate(result):\n",
        "    print(f\"batch {i}:\")\n",
        "    for j, item in enumerate(batch):\n",
        "        print(f\" item {j}: \\n{item}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAtCTz7PkUFA"
      },
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "Произведем бинарную классификацию настроения обзоров фильмов из [IMDb](https://www.imdb.com/). Обзоры будут делиться на два класса negative (0) positive (1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taXSv5QfkUFA"
      },
      "source": [
        "## Загрузка данных IMDb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glOezeSrkUFB"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
        "    name=\"imdb_reviews\", as_supervised=True,\n",
        "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"]\n",
        ")\n",
        "tf.random.set_seed(42)\n",
        "train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n",
        "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
        "test_set = raw_test_set.batch(32).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7sEK0VjkUFB"
      },
      "source": [
        "Keras также включает в себя функцию `tf.keras.datasets.imdb.load_data()` для загрузки датасета IMDb. При этом обзоры уже предобработаны и представлены как последовательности IDs слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96HOCoHXkUFC",
        "outputId": "6f303eef-334a-483f-8603-a7494ac53d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
            "Label: 0\n",
            "I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n",
            "Label: 0\n",
            "Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.\n",
            "Label: 0\n",
            "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n",
            "Label: 1\n"
          ]
        }
      ],
      "source": [
        "for review, label in raw_train_set.take(4):\n",
        "    print(review.numpy().decode(\"utf-8\"))\n",
        "    print(\"Label:\", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxJclwAkUFC"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "Для того, чтобы работать с текстом, необходимо производить препроцессинг. Разбиение текста на отдельные единицы (токены), называется **токенизацией**. В общем-то можно назвать и сегментацией. Для char-RNN мы разбивали текст на отдельные символы. Другой вариант – разбивать на слова, также используя слой `tf.keras.layers.TextVectorization`. При разбиении текста на отдельные слова, используется пробел, для детектирования границ слов. Однако, следует иметь в виду, что это не очень хорошо работает для некоторых языков: в китайском не используются пробелы между словами, а в немецком часто несколько слов сливают в одно слово без пробелов. Даже в английском пробелы не всегда являются хорошим выбором при токенизации текста: например, \"San Francisco\" или \"#ILoveDeepLearning\".\n",
        "\n",
        "**Open Vocabulary Problem** (проблема открытого словаря)  связана со способностью модели работать со словами или фразами, которые не содержатся в предопределенном словаре. Проблема возникает в силу постоянного развития языка и создания новых слов, а так же в связи с тем, что различные области могут обладать специфическими терминами или выражениями, которые не вписываются в другие контексты.\n",
        "\n",
        "К счастью, есть решения этих проблем. В [статье](https://arxiv.org/abs/1508.07909) Rico Sennrich 2016 года было исследовано несколько методов токенизации и детокенизации текста на уровне подслов (*subword level*). В этом подходе, если даже модель сталкивается с незнакомым словом, она все еще может догадаться о его значении. Например, даже если модель никогда не сталкивалась со словом \"smartest\" в процессе обучения, но при этом изучала слово \"smart\" и также изучила, что суффикс \"est\" означает \"the most\", она сможет сделать вывод о значении слова \"smartest\". Одна из таких техник – byte pair encoding (BPE). BPE разделяет весь тренировочный набор на отдельные символы (включая пробелы), затем производит слияние наиболее часто встречающихся пар символов. Далее производится слияние уже объединенных смежных элементов и так далее, пока словарь не достигнет желаемых размеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLasyBgDkUFD"
      },
      "source": [
        "В [статье]() Taku Kudo 2018 года subword tokenization было улучшено. В статье предлагается новая техника регуляризации, названная **subword regularization**, которая улучшает верность и робастность путем внесения некоторой стохастичности в токенизацию в процессе обучения: к примеру, \"New England\" может быть токенизировано как \"New\" + \"England\" или \"New\" + \"Eng\" + \"land\", или просто как \"New England\" (всего один токен). Т.е. токенизация становится не однозначной. То обстоятельство, что в ходе обучения случайным образом выбираются различные сегменты для токенизации, увеличивает лингвистическую вариативность модели.\n",
        "\n",
        "Библиотека [TensorFlow Text](https://www.tensorflow.org/text) ([GitHub](https://github.com/tensorflow/text), [PyPi](https://pypi.org/project/tensorflow-text/)) также реализует различные стратегии токенизации, включая WordPieces (вариант BPE). В [Tokenizers library by Hugging Face](https://huggingface.co/docs/tokenizers/index) реализован широкий спектр предельно быстрых токенизаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Eml5UhkUFE"
      },
      "source": [
        "Для токенизации в задачи классификации обзоров IMDb достаточно будет использовать пробелы для границ токенов. Так что создадим слой TextVectorization и адаптируем его к обучающему набору. Ограничим размер словаря 1000 токенами, включая 998 самых частых слов плюс токен отступа (padding token) и токен неизвестных слов, так как очень маловероятно, что низкочастотные слова будут важны для данной задачи. Ограничение размера словаря снизит число параметров, необходимых модели для обучения::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JeV30_kkUFF",
        "outputId": "288cdab2-5184-486a-ef72-86afe49d4188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([11,  7, 86], dtype=int64)>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = 1000\n",
        "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
        "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))\n",
        "\n",
        "text_vec_layer(\"This is great!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhsxQ_VjkUFG"
      },
      "source": [
        "## Создание и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N80NmotfkUFG",
        "outputId": "cf497791-8d01-4c0d-ea43-96938fd6f6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "704/704 [==============================] - 227s 319ms/step - loss: 0.6935 - accuracy: 0.5040 - val_loss: 0.6930 - val_accuracy: 0.5024\n",
            "Epoch 2/2\n",
            "704/704 [==============================] - 233s 331ms/step - loss: 0.6930 - accuracy: 0.4986 - val_loss: 0.6926 - val_accuracy: 0.5036\n"
          ]
        }
      ],
      "source": [
        "embed_size = 128\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
        "    tf.keras.layers.GRU(128),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viz5duoMkUFH"
      },
      "source": [
        "Слой `TextVectorization` переводит слова в числа (IDs), а слой `Embedding` переводит IDs слов в embeddings. Embedding Matrix должна иметь одну строку на каждый токен в словаре (`vocab_size`) и число колонок, равное размерности (`embed_size`).\n",
        "\n",
        "Как видно из результатов, сеть обучилась крайне плохо: accuracy едва ли отличается от 0.5. С чем это связано? Обзоры фильмов имеют разную длину, и когда слой `TextVectorization` конвертирует их в последовательности IDs токенов, он дополняет отступами короткие рецензии, используя токен отступа (ID 0) для того, чтобы сделать их длину такой же, как и самая длинная последовательность в партии. В результате, большинство последовательностей заканчиваются с большим количеством токенов отступа (это могут быть десятки и даже сотни). И хотя мы используем слой `GRU`, который гораздо лучше, чем слой `SimpleRNN`, его краткосрочная память все еще не так велика. Так что когда он проходит через множество токенов отступа, он забывает, о чем вообще была эта рецензия. Одно из решений – скармливать модели партии, в которых все последовательности имеют равные длины (что также поднимет скорость обучения). Другое решение – игнорирование токенов отступа сетью. Это может быть сделано при помощи маскировок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D-N0Ry1kUFI"
      },
      "source": [
        "## Masking\n",
        "\n",
        "Настроить модель Keras с тем, чтобы она игнорировала токены паддингов, нужно задать `mask_zero=True` при создании слоя `Embedding`. Это значит, что токен паддинга (ID 0) будет проигнорирован всеми последющими слоями. Попробуем заново обучить такую модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhNlkaMIkUFI",
        "outputId": "d274468b-4e6d-40af-d1d6-5084facbdff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\wernadsky\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "704/704 [==============================] - 267s 371ms/step - loss: 0.4786 - accuracy: 0.7676 - val_loss: 0.3876 - val_accuracy: 0.8416\n",
            "Epoch 2/2\n",
            "704/704 [==============================] - 256s 364ms/step - loss: 0.3351 - accuracy: 0.8604 - val_loss: 0.3115 - val_accuracy: 0.8700\n"
          ]
        }
      ],
      "source": [
        "embed_size = 128\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
        "    tf.keras.layers.GRU(128),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ezrhbpIkUFJ"
      },
      "source": [
        "Данный способ работает следующим образом: слой `Embedding` создает **маскирующий тензор** (*mask tensor*) используя функцию `tf.math.not_equal(inputs, 0)`. Эта функция возвращает булевый тензор той же формы, что и `inputs`, в котором все элменты, соответствующие нулю в `inputs`, равны `False`, а все остальные элементы равны `True`. Этот маскирующий тензор автоматически распространяется по модели к следующим слоям, и если их метод `call()` имеет аргумент `mask`, то он автоматически получает этот тензор. Это позволяет слою игнорировать соответствующие временные шаги. Каждый слой может использовать тензор по-разному, но в общем они просто игнорируют замаскированные временные шаги. Например, когда рекуррентный слой сталкивается с замаскированным временным шагом, он просто копирует output из предыдущего временнóго шага.\n",
        "\n",
        "Если атрибут `supports_making` слоя имеет значние `True`, то маска автоматически распространяется к следующему слою. Таким образом, маскирующий тензор распространяется пока слои имеют `supports_making=True`. Например, атрибут `supports_masking` рекуррентного слоя равен `True`, когда `return_sequences=True`, и равен `False`, когда `return_sequences=False`, так как в этом случае уже нет необходимости в масировке.\n",
        "\n",
        "В нашем случае слой `GRU` получит маску автоматически и будет ее использовать, но она не будет распространять ее дальше, так как `return_sequences=False`.\n",
        "\n",
        ">Некоторым слоям необходимо обновить маску перед ее распространением на следующий слой: они делают это путем реализации метода `compute_mask()`, который принимает два аргумента: входные данные и предыдущую маску. Затем он вычисляет обновленную маску и возвращает ее. Метод `compute_mask()` по умолчанию просто возвращает предыдущую маску без изменений.\n",
        "\n",
        "Также можно реализовать пользовательские слои, которые будут поддерживать маски."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6iV4stkUFJ"
      },
      "source": [
        "Слои `LSTM` и `GRU` имеют оптимизированную реализацию для графических процессоров на основе библиотеки cuDNN от Nvidia. Однако эта реализация поддерживает маскирование только в том случае, если все токены отступов находятся в конце последовательностей. Также требуется использовать значения по умолчанию для нескольких гиперпараметров: `activation`, `recurrent_activation`, `recurrent_dropout`, `unroll`, `use_bias` и `reset_after`. В протьивном случае эти слои откатятся к (гораздо более медленной) дефолтной реализации для GPU.\n",
        "\n",
        "Если модель не стартует слоем `Embedding`, то можно использвать слой `tf.keras.Masking`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo56DbJNkUFK"
      },
      "source": [
        "Использование маскирующих слоев и автоматического распространения маски лучше всего подходит для простых моделей. Это не всегда будет работать для более сложных моделей, например, когда нужно смешать слои `Conv1D` с рекуррентными слоями. В таких случаях нужно будет явно вычислить маску и передать ее соответствующим слоям, используя либо Functional API, либо Subclassing API. Например, следующая модель эквивалентна предыдущей модели, за исключением того, что она построена с использованием Functional API и добавляет маскировку вручную. Также добавим немного dropout, поскольку предыдущая модель была немного переобучена:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFvEbTkckUFK"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
        "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "token_ids = text_vec_layer(inputs)\n",
        "mask = tf.math.not_equal(token_ids, 0)\n",
        "Z = tf.keras.layers.Embedding(vocab_size, embed_size)(token_ids)\n",
        "Z = tf.keras.layers.GRU(128, dropout=0.2)(Z, mask=mask)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(Z)\n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-MyFsg7kUFL"
      },
      "source": [
        "**Warnign**: запуск следующей ячейки займет около 30 минут, если не используется GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31AcNA1rkUFL"
      },
      "outputs": [],
      "source": [
        "# extra code – compiles and trains the model, as usual\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hw_6IzJkUFM"
      },
      "source": [
        "Еще один способ маскировки – скармливать модели ragged tensors. На практике, все, что нужно сделать, это установить `ragged=True` при созданиии слоя `TextVectorization`, так что входные последовательности представлены как ragged tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5xOiXGgkUFM",
        "outputId": "c4232879-fda1-4855-ff26-2c2d9d29d2d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[86, 18], [11, 7, 1, 116, 217]]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer_ragged = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_size, ragged=True)\n",
        "text_vec_layer_ragged.adapt(train_set.map(lambda reviews, labels: reviews))\n",
        "text_vec_layer_ragged([\"Great movie!\", \"This is DiCaprio's best role.\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORl8_gm6kUFN",
        "outputId": "f010c8ab-74cd-4815-fc4e-0a3c5e43a293"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              "array([[ 86,  18,   0,   0,   0],\n",
              "       [ 11,   7,   1, 116, 217]], dtype=int64)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer([\"Great movie!\", \"This is DiCaprio's best role.\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih2yNlR_kUFO",
        "outputId": "f66c929f-b2c2-4ef5-ea1c-b7a637810a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[86, 18], [11, 7, 1, 116, 217]]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer_ragged([\"Great movie!\", \"This is DiCaprio's best role.\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoVXuNPykUFQ"
      },
      "source": [
        "**Warnign**: запуск следующей ячейки займет около 30 минут, если не используется GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ebRL71AkUFR"
      },
      "outputs": [],
      "source": [
        "embed_size = 128\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    text_vec_layer_ragged,\n",
        "    tf.keras.layers.Embedding(vocab_size, embed_size),\n",
        "    tf.keras.layers.GRU(128),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfa1CBCikUFS"
      },
      "source": [
        "Рекуррентные слои Keras имеют встроенную поддержку для ragged tensors, так что нет необходимости передавать `mask_zero=True` или вручную задавать явноя маски, достаточно просто использовать слой `TextVectorization` в модели. Однако, так как поддержка ragged tensors в Keras была добавлена недавно, могут возникать ньюансы. В частности, на момент конспекта еще не было возможности использовать ragged tensors как targets при запуске на GPU (но верятно это в скором времени будет исправлено).\n",
        "\n",
        ">Если использовать `tf.keras.callbacks.TensorBoard()`, то можно визуализировать embeddings в TensorBoard в ходе обучения, и видеть, как некоторые слова постепенно образуют кластеры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HtzF256kUFS"
      },
      "source": [
        "## Reusing Pretrained Embeddings and Language Models\n",
        "\n",
        "Вместо обучения embeddings слов, мы можем просто загрузить и использовать предобученные embeddings, такие как гугловский [Word2vec embeddings](https://www.tensorflow.org/text/tutorials/word2vec), Стенфордский [GloVe embeddings](https://nlp.stanford.edu/projects/glove/), или [FastText embeddings](https://fasttext.cc/) от Facebook.\n",
        "\n",
        "Использование предобученных embeddings слов было популярно в течение нескольких лет, однако этот подход имеет свои ограничения. На практике слова имеют единственное представление, не учитывающее контекст (в том числе и омонимы). К примеру, слово \"right\" будет кодироваться одинаково как в случае \"left and right\" так и для \"right and wrong\", хотя слово имеет совершенное разные значения в этих двух контекстах. Это ограничение было устранено в [статье](https://arxiv.org/abs/1802.05365v2) Matthew Peters, в которой были введены Embeddings from Language Models (ELMo), которые представляют собой контекстуализированные embeddings слов, извлеченные из внутренних состояний глубокой двунаправленной (*bidirectional*) языковой модели. Вместо использования предобученных embeddings слов в модели, используется часть предобученной языковой модели.\n",
        "\n",
        "Примерно в то же время в [статье](https://arxiv.org/abs/1801.06146) Jeremy Howard и Sebastian Ruder было продемонстрирована эффективность предварительного обучения без учителя для задач NLP: авторы обучили языковую модель LSTM на огромных корпусах текстов используя self-supervised learning (генерируя метки автоматически из данных), затем они надстраививали (fine-tune) модель под различные задачи (Universal Language Model Fine-Tuning – ULMFiT). Их модель превзошла современные модели в шести задачах классификации, причем, с болшим отрывом (сократив ошибку на 18-24% в большинстве случаев). Более того, авторы показали, что предобученная модель надстроенная всего на 100 размеченных образцах могла достичь тех же результатов, что и аналогичная модель, обученная с нуля на 10000 образцов. Прежде, использование предобученных моделей было нормой только в компьютерном зрении. Данная статья обозначила начало новой эры NLP: сегодня переиспользование предобученных языковых моделей является нормой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3q6X0AkkUFT"
      },
      "source": [
        "В качестве примера построим классификатор на базе Universal Sentence Encoder – модели, введеной исследователями Google в [статье](https://arxiv.org/abs/1803.11175). Эта модель основан на архитектуре трансформеров. Модель доступна на TensorFlow Hub.\n",
        "\n",
        ">Эта модель довольно велика – около 1 GB, так что загрузка может занять некоторое время. По умолчанию, модули TensorFlow Hub сохраняются во временной директории и загрузка повторятся каждый раз, когда запускается программа. Для того, чтобы этого избежать, необходимо задать переменной окружения `TFHUB CACHE DIR` директорию: модули будут тогда сохраняться в этой директории и загружаться лишь один раз."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcWwVWoGkUFU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "os.environ[\"TFHUB_CACHE_DIR\"] = 'tfhub_cache'\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                   trainable=True, dtype=tf.string, input_shape=[]),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x3hUCpUkUFU"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_set, validation_data=valid_set, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1mqdumEkUFV"
      },
      "source": [
        "Заметим, что последняя часть URL-адреса модуля TensorFlow Hub указывает, что нам нужна версия модели 4. Такое управление версиями гарантирует, что если новая версия модуля будет выпущена на TF Hub, это не сломает нашу модель. Если ввести этот URL-адрес в веб-браузере,  то откроется документация этого модуля.\n",
        "\n",
        "Установка аргумента `trainable=True` при создании слоя `hub.KerasLayer` позволяет производить надстройку (fine-tuning) Universal Sentence Encoder в процессе обучения: некоторые его веса будут подкручены обратным распространением ошибки. Не все модули из TF Hub поддерживают надстройку, так что следует сначала убедиться в документации.\\\n",
        "\n",
        "После обучения этп модель должна достичь accuracy выше 90% на валидационных данных. Это довольно хороший результат: если попробовать произвести классификацию самостоятельно, то результат будет не намного выше, так как многие рецензии содержат как положительные, так и отрицательные комментарии. Классификация таких двусмысленных рецензий схоже с бросанием монеты."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}